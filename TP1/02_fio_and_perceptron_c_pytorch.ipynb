{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitbertelsmannpipenv047cab295b6f4a41934b5c40025a08a1",
   "display_name": "Python 3.7.5 64-bit ('bertelsmann': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 6.579452542351631\n1 4.55365868135625\n2 3.5146060244998543\n3 3.073287871156409\n4 2.8411840586341865\n5 2.678216563891038\n6 2.543810985089184\n7 2.4253356075723937\n8 2.3182391599256347\n9 2.2204776676175606\n10 2.1308408803963315\n11 2.0484290700599894\n12 1.972487307938247\n13 1.9023522424592971\n14 1.8374334068002942\n15 1.7772044564957035\n16 1.7211969572693042\n17 1.6689947653970811\n18 1.6202286388174403\n19 1.57457111575548\n20 1.531731749879433\n21 1.4914527608371781\n22 1.453505121442003\n23 1.417685074912665\n24 1.3838110583770653\n25 1.3517209997287154\n26 1.321269951202642\n27 1.2923280226773592\n28 1.264778579313498\n29 1.2385166707913524\n30 1.2134476625280803\n31 1.1894860424841454\n32 1.1665543802985865\n33 1.1445824184094973\n34 1.1235062774653752\n35 1.103267760697456\n36 1.08381374400745\n37 1.0650956403462273\n38 1.0470689285399573\n39 1.0296927380864236\n40 1.012929482620926\n41 0.9967445357624303\n42 0.9811059439183845\n43 0.9659841713706552\n44 0.9513518736027419\n45 0.9371836953750627\n46 0.9234560905238218\n47 0.9101471608611424\n48 0.8972365118994892\n49 0.8847051234202878\n50 0.8725352331621006\n51 0.8607102321238318\n52 0.8492145701683552\n53 0.8380336707760113\n54 0.8271538539394001\n55 0.8165622663138694\n56 0.8062468178448692\n57 0.7961961241860882\n58 0.7863994543030606\n59 0.7768466827273228\n60 0.7675282459876764\n61 0.7584351027988685\n62 0.7495586976350932\n63 0.7408909273570117\n64 0.73242411059729\n65 0.7241509596415607\n66 0.7160645545698721\n67 0.7081583194484993\n68 0.7004260003839474\n69 0.6928616452703811\n70 0.6854595850789464\n71 0.6782144165527086\n72 0.6711209861845225\n73 0.6641743753672185\n74 0.6573698866162787\n75 0.6507030307747537\n76 0.6441695151187967\n77 0.6377652322898304\n78 0.6314862499862764\n79 0.6253288013539253\n80 0.6192892760195803\n81 0.6133642117175744\n82 0.607550286463263\n83 0.601844311231614\n84 0.5962432231026763\n85 0.5907440788389954\n86 0.5853440488630153\n87 0.58004041160521\n88 0.5748305481961155\n89 0.5697119374776606\n90 0.5646821513111926\n91 0.5597388501614258\n92 0.5548797789372073\n93 0.5501027630714926\n94 0.5454057048243229\n95 0.5407865797938356\n96 0.5362434336214996\n97 0.5317743788788171\n98 0.5273775921236864\n99 0.5230513111155095\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Training data for AND in the form [x1, x2, bias=1]\n",
    "x = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=float)\n",
    "y = torch.tensor([[0.], [0.], [0.], [1.]])\n",
    "w = torch.randn(3, 1, dtype=float, requires_grad=True)\n",
    "\n",
    "lr = .3\n",
    "for t in range(100):\n",
    "    y_pred = x.mm(w).sigmoid()\n",
    "    ll = y * y_pred + (1 - y) * (1 - y_pred)\n",
    "    loss = -ll.log().sum()      # The loss value.\n",
    "    print(t, loss.item())\n",
    "    loss.backward()             # Compute the gradients of the loss.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad       # Update weights using SGD.        \n",
    "        w.grad.zero_()          # Clear the gradients for the next iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0061],\n        [0.1374],\n        [0.1372],\n        [0.8047]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mm(w).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1817],\n        [0.2072],\n        [0.2072],\n        [0.4039]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mm(w).sigmoid().softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}