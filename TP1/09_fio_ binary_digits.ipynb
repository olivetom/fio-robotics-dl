{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([10, 5, 3]) torch.Size([10])\ntorch.Size([10, 15]) torch.Size([10])\n"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create Tensors to hold inputs and outputs for digits\n",
    "x = torch.FloatTensor([\n",
    "    [[1, 1, 1], #0\n",
    "    [1, 0, 1], \n",
    "    [1, 0, 1], \n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1]], \n",
    "    \n",
    "    [[0, 0, 1], #1\n",
    "    [0, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #2\n",
    "    [0, 0, 1], \n",
    "    [0, 1, 0], \n",
    "    [1, 0, 0], \n",
    "    [1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #3\n",
    "    [0, 0, 1], \n",
    "    [1, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [1, 1, 1]],\n",
    "    \n",
    "    [[1, 0, 1], #4\n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [0, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #5\n",
    "    [1, 0, 0], \n",
    "    [1, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #6\n",
    "    [1, 0, 0], \n",
    "    [1, 1, 1], \n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #7\n",
    "    [0, 0, 1], \n",
    "    [0, 1, 0], \n",
    "    [1, 0, 0], \n",
    "    [1, 0, 0]],\n",
    "\n",
    "    [[1, 1, 1], #8\n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1], \n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 1], #9\n",
    "    [1, 0, 1], \n",
    "    [1, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [0, 0, 1]]])\n",
    "\n",
    "y = torch.LongTensor([0, 1, 2, 3, 4, \n",
    "                5, 6, 7, 8, 9])\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "x = x.view(x.shape[0], -1)\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(2.3181, grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(15, 13),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(13, 11),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(11, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(x)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(2.3199, grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(15, 13),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(13, 11),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(11, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(x)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(15, 13),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(13, 11),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(11, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "logps = model(x)\n",
    "loss = criterion(logps, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Before backward pass: \n None\nAfter backward pass: \n tensor([[-0.0037,  0.0035, -0.0077, -0.0060, -0.0041, -0.0089, -0.0037, -0.0037,\n         -0.0077,  0.0000,  0.0000, -0.0077,  0.0035,  0.0035, -0.0077],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0017,  0.0017,  0.0100,  0.0000,  0.0083,  0.0100,  0.0000,  0.0017,\n          0.0083,  0.0017,  0.0000,  0.0083,  0.0017,  0.0000,  0.0083],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0051,  0.0039,  0.0073,  0.0131,  0.0022,  0.0061,  0.0078, -0.0101,\n          0.0100, -0.0063,  0.0000,  0.0100, -0.0031, -0.0087,  0.0017],\n        [-0.0170, -0.0170, -0.0170,  0.0000,  0.0000, -0.0170,  0.0000, -0.0170,\n          0.0000, -0.0170,  0.0000,  0.0000, -0.0170,  0.0000,  0.0000],\n        [-0.0033, -0.0105,  0.0072,  0.0005,  0.0105,  0.0039, -0.0060, -0.0055,\n          0.0045, -0.0024,  0.0000,  0.0045, -0.0056, -0.0123,  0.0005],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-0.0037, -0.0082, -0.0043, -0.0036, -0.0005, -0.0036, -0.0031, -0.0012,\n         -0.0036, -0.0082,  0.0000, -0.0036, -0.0017,  0.0046,  0.0021],\n        [ 0.0080,  0.0127, -0.0009,  0.0023, -0.0089,  0.0039,  0.0080,  0.0079,\n         -0.0009,  0.0159,  0.0000, -0.0009,  0.0081,  0.0081, -0.0009],\n        [-0.0096, -0.0096, -0.0096, -0.0096,  0.0000,  0.0000, -0.0096, -0.0096,\n         -0.0096, -0.0096,  0.0000, -0.0096, -0.0096, -0.0096, -0.0096],\n        [ 0.0041,  0.0051,  0.0090,  0.0049,  0.0048,  0.0012,  0.0114, -0.0019,\n          0.0163,  0.0070,  0.0000,  0.0163,  0.0132,  0.0116,  0.0074]])\n"
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the network!\n",
    "\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Initial weights -  Parameter containing:\ntensor([[-3.1761e-01, -6.5274e-01, -4.6811e-01,  4.2604e-01,  1.4061e-01,\n          1.2140e+00, -4.1593e-01,  2.6078e+00, -3.5011e-01,  1.4083e-01,\n          5.2977e-02, -4.3784e-01, -5.3717e-01,  6.3714e-01,  1.0747e+00],\n        [-2.3521e-01,  1.3545e-01,  1.2190e-01, -1.5839e-01,  5.8536e-01,\n          1.1407e+00, -1.3661e+00,  9.6107e-01, -6.9325e-01,  4.6395e+00,\n          2.2145e-01, -6.8543e-01,  9.3831e-01,  4.6617e-01,  2.1689e-01],\n        [ 8.7146e-01,  8.1826e-01,  5.1984e-01,  7.3994e-01, -9.0716e-01,\n         -5.5008e-01,  1.4793e+00, -1.5921e+00,  9.0604e-01, -1.0692e+00,\n          1.4049e-01,  1.0482e+00,  3.8220e-01,  6.1204e-01,  2.5061e-01],\n        [-1.5989e-01, -3.8103e-02,  1.8927e-01, -2.2989e-01,  3.4840e-02,\n          1.6149e-01,  6.9545e-02,  4.8231e-02, -3.9307e-02,  4.6381e-03,\n         -1.0283e-02, -2.2207e-01, -2.0040e-01, -7.7899e-02,  8.6175e-02],\n        [ 1.4780e-01, -9.8956e-02,  9.4070e-02,  5.1845e-02,  6.3365e-02,\n         -4.8955e-02, -1.4105e-01,  1.1422e-01, -1.4674e-01, -2.5790e-01,\n         -1.3692e-01, -4.0150e-02, -2.1940e-01, -1.4274e-01, -1.3861e-01],\n        [-6.8698e-02, -2.6601e-01,  2.4686e-02,  3.8091e-01,  7.0378e-02,\n          7.3329e-03,  1.0522e-01,  2.6046e-01,  2.3902e-01,  4.6244e-01,\n          5.2762e-02,  4.4413e-01, -2.2279e-01,  1.0265e+00,  7.8371e-01],\n        [-4.6821e-01, -5.6466e-01,  6.4605e-01, -2.3933e-01,  1.0622e+00,\n          8.0930e-01, -4.4349e-01, -1.7207e-01,  9.5615e-01, -2.8485e-01,\n         -9.9349e-02,  8.5560e-01, -9.6903e-01, -9.3009e-01,  7.0320e-01]],\n       requires_grad=True)\nGradient - tensor([[-3.3726e-05,  3.7148e-04, -2.3831e-04, -5.9006e-04, -2.0458e-04,\n          1.5164e-03, -9.1344e-05, -6.4172e-04, -2.9592e-04, -1.3668e-04,\n          0.0000e+00, -2.9592e-04, -9.5506e-04, -1.2923e-03, -5.7554e-04],\n        [ 7.0301e-03,  7.0301e-03,  6.6494e-03,  6.6863e-03, -3.8072e-04,\n          2.1786e-03,  7.0617e-03,  6.7857e-03,  6.6809e-03, -3.0901e-04,\n          0.0000e+00,  6.6809e-03,  5.0539e-03,  5.1573e-03,  6.7528e-03],\n        [-2.1955e-03, -2.4993e-03, -1.8662e-03, -1.4826e-03,  3.2924e-04,\n         -2.1566e-03, -2.2761e-03, -1.6563e-03, -1.9468e-03,  2.2301e-04,\n          0.0000e+00, -1.9468e-03, -7.5148e-04, -7.5148e-04, -1.8662e-03],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 9.6502e-04,  1.0181e-03,  8.9370e-04,  7.9264e-04, -7.1321e-05,\n          3.9612e-04,  9.0393e-04,  8.9471e-04,  8.3261e-04, -5.7453e-05,\n          0.0000e+00,  8.3261e-04,  6.4816e-04,  4.1376e-04,  6.5930e-04],\n        [ 7.1681e-04,  1.0778e-03,  6.2085e-04,  6.0730e-04, -9.5967e-05,\n          6.2085e-04,  7.1681e-04,  2.8105e-04,  6.2085e-04,  1.4438e-04,\n          0.0000e+00,  6.2085e-04,  2.5389e-04,  2.5389e-04,  6.2085e-04]])\n"
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = x, y\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Updated weights -  Parameter containing:\ntensor([[-3.1761e-01, -6.5274e-01, -4.6811e-01,  4.2604e-01,  1.4061e-01,\n          1.2140e+00, -4.1593e-01,  2.6078e+00, -3.5011e-01,  1.4083e-01,\n          5.2977e-02, -4.3784e-01, -5.3717e-01,  6.3714e-01,  1.0747e+00],\n        [-2.3521e-01,  1.3545e-01,  1.2190e-01, -1.5839e-01,  5.8536e-01,\n          1.1407e+00, -1.3661e+00,  9.6107e-01, -6.9325e-01,  4.6395e+00,\n          2.2145e-01, -6.8543e-01,  9.3831e-01,  4.6617e-01,  2.1689e-01],\n        [ 8.7146e-01,  8.1826e-01,  5.1984e-01,  7.3994e-01, -9.0716e-01,\n         -5.5008e-01,  1.4793e+00, -1.5921e+00,  9.0604e-01, -1.0692e+00,\n          1.4049e-01,  1.0482e+00,  3.8220e-01,  6.1204e-01,  2.5061e-01],\n        [-1.5989e-01, -3.8103e-02,  1.8927e-01, -2.2989e-01,  3.4840e-02,\n          1.6149e-01,  6.9545e-02,  4.8231e-02, -3.9307e-02,  4.6381e-03,\n         -1.0283e-02, -2.2207e-01, -2.0040e-01, -7.7899e-02,  8.6175e-02],\n        [ 1.4780e-01, -9.8956e-02,  9.4070e-02,  5.1845e-02,  6.3365e-02,\n         -4.8955e-02, -1.4105e-01,  1.1422e-01, -1.4674e-01, -2.5790e-01,\n         -1.3692e-01, -4.0150e-02, -2.1940e-01, -1.4274e-01, -1.3861e-01],\n        [-6.8698e-02, -2.6601e-01,  2.4686e-02,  3.8091e-01,  7.0378e-02,\n          7.3329e-03,  1.0522e-01,  2.6046e-01,  2.3902e-01,  4.6244e-01,\n          5.2762e-02,  4.4413e-01, -2.2279e-01,  1.0265e+00,  7.8371e-01],\n        [-4.6821e-01, -5.6466e-01,  6.4605e-01, -2.3933e-01,  1.0622e+00,\n          8.0930e-01, -4.4349e-01, -1.7207e-01,  9.5615e-01, -2.8485e-01,\n         -9.9349e-02,  8.5560e-01, -9.6903e-01, -9.3009e-01,  7.0320e-01]],\n       requires_grad=True)\n"
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epoch:0, Training loss: 2.306408405303955\nepoch:500, Training loss: 1.4523013830184937\nepoch:1000, Training loss: 0.8487351536750793\nepoch:1500, Training loss: 0.5815219283103943\nepoch:2000, Training loss: 0.4624112546443939\nepoch:2500, Training loss: 0.4174840450286865\nepoch:3000, Training loss: 0.3949768543243408\nepoch:3500, Training loss: 0.381454735994339\nepoch:4000, Training loss: 0.3723662197589874\nepoch:4500, Training loss: 0.36590707302093506\nepoch:5000, Training loss: 0.36107224225997925\nepoch:5500, Training loss: 0.35734423995018005\nepoch:6000, Training loss: 0.3543396592140198\nepoch:6500, Training loss: 0.20576202869415283\nepoch:7000, Training loss: 0.049119800329208374\nepoch:7500, Training loss: 0.023886673152446747\nepoch:8000, Training loss: 0.01552845723927021\nepoch:8500, Training loss: 0.011382844299077988\nepoch:9000, Training loss: 0.008950436487793922\nepoch:9500, Training loss: 0.007335667498409748\nepoch:9999, Final Training loss: 0.006221638526767492\n"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(15, 7),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(7, 5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "epochs = 10000\n",
    "x_train = x\n",
    "y_train = y\n",
    "for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (e % 500) == 0:\n",
    "            print(f\"epoch:{e}, Training loss: {running_loss}\")\n",
    "        idx = torch.randperm(x_train.shape[0])\n",
    "        x_train = x_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "else: print(f\"epoch:{e}, Final Training loss: {running_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[0., 0., 1.],\n        [0., 1., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]])\nInput digit:1. Predicted digit:1\n"
    }
   ],
   "source": [
    "i = torch.randint(0,9,(1,))\n",
    "digit = x[i].view(1, 15)\n",
    "print(digit.view(5,-1))\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(digit)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "#print(logps, ps, ps.sum())\n",
    "print(f\"Input digit:{i.item()}. Predicted digit:{torch.argmax(ps).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images. Next up you'll write the code for training a neural network on a more complex dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('deep-learning-v2-pytorch': pipenv)",
   "language": "python",
   "name": "python37564bitdeeplearningv2pytorchpipenv228bb8fd2b7044fc95b1a54da7d30e8a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}